{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8602130,"sourceType":"datasetVersion","datasetId":5137337},{"sourceId":8604711,"sourceType":"datasetVersion","datasetId":5136208},{"sourceId":61578,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":50688}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc \nfrom glob import glob\nfrom pathlib import Path\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nimport lightgbm\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom catboost import CatBoostClassifier, Pool\nimport xgboost\nfrom collections import Counter\n\nimport shap\nimport pickle\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T08:06:50.115768Z","iopub.execute_input":"2024-06-06T08:06:50.116156Z","iopub.status.idle":"2024-06-06T08:07:00.423261Z","shell.execute_reply.started":"2024-06-06T08:06:50.116128Z","shell.execute_reply":"2024-06-06T08:07:00.422110Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT            = Path(\"/kaggle/input/home-credit-risk-model-train-test\")\nSCHEMA_PATH     = Path(\"/kaggle/input/schema-home-credit-risk-data\")\nMODEL           = Path(\"/kaggle/input/homecredit-risk-model-stability/other/catboost_lgb_champ/3\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:07:00.425521Z","iopub.execute_input":"2024-06-06T08:07:00.426277Z","iopub.status.idle":"2024-06-06T08:07:00.432465Z","shell.execute_reply.started":"2024-06-06T08:07:00.426233Z","shell.execute_reply":"2024-06-06T08:07:00.431217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_data_types(df, schema):\n    \n    for col, dtype in schema.items():\n        if dtype == 'category':\n            dtype = 'object'\n        df[col] = df[col].astype(dtype, errors = 'ignore')\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:07:00.433672Z","iopub.execute_input":"2024-06-06T08:07:00.434694Z","iopub.status.idle":"2024-06-06T08:07:00.445814Z","shell.execute_reply.started":"2024-06-06T08:07:00.434654Z","shell.execute_reply":"2024-06-06T08:07:00.444537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pl.read_csv(ROOT/'model_abt_train.csv').to_pandas()\nX_test = pl.read_csv(ROOT/'model_abt_test.csv').to_pandas()\n\nschema = pd.read_csv(SCHEMA_PATH / \"data_schema.csv\", names = ['Columns', 'dtype'])\nschema = schema[schema['Columns'].isin(X.columns)]\nschema = schema.set_index('Columns')['dtype'].to_dict()\n\nX = set_data_types(X, schema)\nX_test = set_data_types(X_test, schema)\ndel schema","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:07:00.448647Z","iopub.execute_input":"2024-06-06T08:07:00.449038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_val = X[['case_id', 'WEEK_NUM']]\nid_test_val = X_test[['case_id', 'WEEK_NUM']]\n\ny = X['target']\ny_test = X_test['target']\n\ncols = X.drop(['case_id', 'WEEK_NUM', 'target', 'decision_month', 'decision_weekday'], axis = 1).columns\n\nX = X.drop(['case_id', 'WEEK_NUM', 'target', 'decision_month', 'decision_weekday'], axis = 1)\nX_test = X_test.drop(['case_id', 'WEEK_NUM', 'target', 'decision_month', 'decision_weekday'], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(ROOT/'cat_cols.pkl', 'rb') as f:\n    cat_cols = pickle.load(f)\nnum_cols = [x for x, dtypes in X.dtypes.items() if dtypes in ['float', 'int']]\nX[cat_cols] = X[cat_cols].astype(str)\nX_test[cat_cols] = X_test[cat_cols].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:32:45.888544Z","iopub.execute_input":"2024-06-06T07:32:45.889046Z","iopub.status.idle":"2024-06-06T07:33:03.593482Z","shell.execute_reply.started":"2024-06-06T07:32:45.889009Z","shell.execute_reply":"2024-06-06T07:33:03.592146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model_Utils:\n    @staticmethod\n    def model_evals(y_true, y_proba, cutoff = 0.5):\n        from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, average_precision_score, roc_auc_score\n        \"\"\"\n        Returns model evaluation metrics for a binary classification model\n\n        Parameters:\n        -----------\n            y_true: int (0,1) \n                Actual binary labels\n\n            y_proba: float (between 0 and 1)\n                Probability scores output of model \n\n        Returns:\n        --------\n            result: dict\n                Dictionary of metrics and their results based on the input\n                    - event rate (% predicted 1's)\n                    - accuracy\n                    - roc_auc\n                    - pr_auc\n                    - recall\n                    - precision\n                    - f1\n                    - lift\n        \"\"\"\n\n        y_pred = (y_proba > cutoff).astype(int)\n\n        event_rate = y_pred.mean()\n\n        accuracy = accuracy_score(y_true, y_pred)\n\n        roc_auc = roc_auc_score(y_true, y_proba)\n\n        pr_auc = average_precision_score(y_true, y_proba)\n\n        recall = recall_score(y_true, y_pred)\n\n        precision = precision_score(y_true, y_pred)\n\n        f1 = f1_score(y_true, y_pred)\n\n        lift = recall / event_rate\n\n        return {'event_rate': event_rate,\n                'acc': accuracy, \n                'precision': precision, \n                'recall': recall, \n                'f1': f1, \n                'roc_auc': roc_auc,\n                'pr_auc': pr_auc, \n                'lift': lift}\n    \n    @staticmethod\n    def cutoff_perc(y_actual, y_proba, percent):\n        n_cutoff = int(len(y_actual) * percent)\n\n        scores = pd.DataFrame({'actual': y_actual, 'proba': y_proba})\n        scores = scores.sort_values(by = 'proba', ascending= False)\n        scores['rank'] = scores['proba'].rank(ascending = False)\n        scores['ranked_pred'] = np.where(scores['rank']<= n_cutoff, 1, 0)\n\n        print(len(scores[scores['ranked_pred'] == 1]))\n        print(scores[scores['ranked_pred'] == 1]['proba'].min())\n        return Model_Utils.model_evals(y_actual, y_proba, cutoff = scores[scores['ranked_pred'] == 1]['proba'].min())\n    \n    @staticmethod\n    def DumbClassifier(y_true):\n        import numpy as np\n        y_pred = np.zeros(len(y_true))\n        return y_pred\n    \n    @staticmethod\n    def RandomChanceClassifier(y_true):\n        import numpy as np\n        y_pred = Model_Utils.DumbClassifier(y_true)\n        event = y_true.sum()\n        ind = np.random.randint(0, len(y_true), size=event)\n        y_pred[ind] = 1\n        return y_pred\n    \n    @staticmethod\n    def save_model_results(results, schema, filepath):\n        if not os.path.exists(filepath):\n            score_schema = {'model_name': 'str', \n                        'model': 'str',\n                        'params': 'str',\n                        'acc': 'float',\n                        'precision': 'float',\n                        'recall': 'float',\n                        'f1_score': 'float',\n                        'roc_auc': 'float',\n                        'pr_auc': 'float',\n                        'lift': 'float'}\n            scores = pd.DataFrame(columns = score_schema.keys()).astype(score_schema)\n        else:\n            scores = pd.read_csv(filepath)\n        row = []\n        \n        for key in schema.keys():\n            row.append(results[key])\n        \n        scores.loc[len(scores)] = row\n        scores.to_csv(filepath, index = False)\n        \n    @staticmethod\n    def LightGBMClassifier_CV(X, y, cat_cols, cv = 5, group = None, params = None):\n        import lightgbm\n        from sklearn.model_selection import StratifiedGroupKFold\n        \n        cv = StratifiedGroupKFold(n_splits=cv, shuffle = True, random_state = 42)\n        \n        if params == None:\n            params = {'random_state': 42\n                     ,'objective': 'binary'\n                     ,'verbose': -1\n                     ,'n_jobs': -1}\n        \n        scores = {'acc': [],\n                        'precision': [],\n                        'recall': [],\n                        'f1': [],\n                        'roc_auc': [],\n                        'pr_auc': [],\n                        'lift': []}\n\n        split = 1\n        \n        for train_ind, valid_ind in cv.split(X, y, groups=group):\n            X_train, y_train = X.iloc[train_ind], y.iloc[train_ind]\n            X_valid, y_valid = X.iloc[valid_ind], y.iloc[valid_ind]\n\n            X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n            X_valid[cat_cols] = X_valid[cat_cols].astype(\"category\")\n            \n            lgb = lightgbm.LGBMClassifier(**params)\n            lgb.fit(X_train, y_train)\n\n            y_proba = lgb.predict_proba(X_valid)[:, 1]\n            results = Model_Utils.model_evals(y_valid, y_proba)\n            print(f'LightGBM, Val CV{split}: {results}\"')\n            \n            split += 1\n            \n            for key in results.keys():\n                if key in scores.keys():\n                    scores[key].append(results[key])\n        \n        for key in results.keys():\n            if key in scores.keys():\n                scores[key] = np.array(scores[key]).mean()\n            \n        print(f'LightGBM, Average CV: {scores}\"')\n        return lgb, scores\n\n    \n    @staticmethod\n    def LightGBMClassifier_pred(X, y, X_test, y_test, cat_cols, params = None):\n        import lightgbm\n        \n        if params == None:\n            params = {'random_state': 42\n                     ,'objective': 'binary'\n                     ,'verbose': -1\n                     ,'n_jobs': -1}\n        \n        scores = {'acc': [],\n                        'precision': [],\n                        'recall': [],\n                        'f1': [],\n                        'roc_auc': [],\n                        'pr_auc': [],\n                        'lift': []}\n\n        \n        X[cat_cols] = X[cat_cols].astype(\"category\")\n        X_test[cat_cols] = X_test[cat_cols].astype(\"category\")\n            \n        lgb = lightgbm.LGBMClassifier(**params)\n        lgb.fit(X, y)\n\n        y_proba = lgb.predict_proba(X_test)[:, 1]\n        results = Model_Utils.model_evals(y_test, y_proba)\n        print(f'LightGBM, Test: {results}\"')\n        \n        return lgb, y_proba, results\n    \n    \n    @staticmethod\n    def CatBoostClassifier_CV(X, y, cat_cols, cv = 5, group = None, params = None):\n        import catboost\n        from sklearn.model_selection import StratifiedGroupKFold\n        \n        cv = StratifiedGroupKFold(n_splits=cv, shuffle = True, random_state = 42)\n        \n        if params == None:\n             params = {'boosting_type' : \"Plain\",\n                      'eval_metric': 'PRAUC',\n                      'random_seed': 42,\n                      'learning_rate': 0.05,\n                      'use_best_model': True,\n                      'iterations': 1000}\n        \n        scores = {'acc': [],\n                        'precision': [],\n                        'recall': [],\n                        'f1': [],\n                        'roc_auc': [],\n                        'pr_auc': [],\n                        'lift': []}\n\n        split = 1\n        \n        for train_ind, valid_ind in cv.split(X, y, groups=group):\n            X_train, y_train = X.iloc[train_ind], y.iloc[train_ind]\n            X_valid, y_valid = X.iloc[valid_ind], y.iloc[valid_ind]\n            \n            \n            clf = CatBoostClassifier(**params)\n        \n            train_pool = Pool(X_train, y_train, cat_features=cat_cols)\n            val_pool = Pool(X_valid, y_valid, cat_features=cat_cols)\n            \n            clf.fit(train_pool, eval_set=val_pool, verbose=False)\n            \n            y_proba = clf.predict_proba(X_valid)[:, 1]\n            results = Model_Utils.model_evals(y_valid, y_proba)\n            print(f'CatBoost, Val CV{split}: {results}\"')\n            \n            split += 1\n            \n            for key in results.keys():\n                if key in scores.keys():\n                    scores[key].append(results[key])\n        \n        for key in results.keys():\n            if key in scores.keys():\n                scores[key] = np.array(scores[key]).mean()\n            \n        print(f'CatBoost, Average CV: {scores}\"')\n        return clf, scores\n    \n    \n    @staticmethod\n    def CatBoostClassifier_pred(X, y, X_test, y_test, cat_cols, params = None):\n        import catboost\n    \n        if params == None:\n             params = {'boosting_type' : \"Plain\",\n                      'eval_metric': 'PRAUC',\n                      'random_seed': 42,\n                      'learning_rate': 0.05,\n                      'use_best_model': True,\n                      'iterations': 1000}\n                \n        clf = CatBoostClassifier(**params)\n        \n        train_pool = Pool(X, y, cat_features=cat_cols)\n        test_pool = Pool(X_test, y_test, cat_features=cat_cols)\n            \n        clf.fit(train_pool, eval_set=test_pool, verbose=False)\n            \n        y_proba = clf.predict_proba(X_test)[:, 1]\n        results = Model_Utils.model_evals(y_test, y_proba)\n        print(f'CatBoost, Test: {results}\"')\n            \n        return clf, y_proba, results\n\n    \n    @staticmethod\n    def train_test_split(X, y, test_size = 0.2):\n        from sklearn.model_selection import train_test_split\n        import polars as pl\n        \n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n        pl.from_pandas(pd.concat([y_train, X_train], axis = 1)).write_csv('model_abt_train.csv')\n        del X_train\n        del y_train\n        gc.collect()\n        \n        pl.from_pandas(pd.concat([y_test, X_test], axis = 1)).write_csv('model_abt_test.csv')\n        del X_test\n        del y_test\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:33:27.194447Z","iopub.execute_input":"2024-06-06T07:33:27.194890Z","iopub.status.idle":"2024-06-06T07:33:27.244338Z","shell.execute_reply.started":"2024-06-06T07:33:27.194823Z","shell.execute_reply":"2024-06-06T07:33:27.243172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params_lgb = {'colsample_bytree': 0.8091363920278533, \n              'gamma': 1.6740930883959255, \n              'learning_rate': 0.0816628382148218, \n              'max_depth': 7, 'min_child_weight': 1.7065771300111194, \n              'n_estimators': 250, 'random_state': 42, \n              'reg_alpha': 7.114616964626139, 'reg_lambda': 8.853463059493436, \n              'subsample': 0.5494975675591438, 'verbose': -1}\n\n\nparams_catboost = {'bagging_temperature': 3.0469773840224983,\n                   'boosting_type': 'Ordered', \n                   'border_count': 96, \n                   'colsample_bylevel': 0.5008191566781925, \n                   'depth': 5, 'iterations': 250, \n                   'l2_leaf_reg': 8.0, \n                   'learning_rate': 0.19362752313765308, \n                   'max_ctr_complexity': 5.0, \n                   'one_hot_max_size': 50, \n                   'random_state': 42, \n                   'verbose': -1}","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:33:29.863054Z","iopub.execute_input":"2024-06-06T07:33:29.863580Z","iopub.status.idle":"2024-06-06T07:33:29.872546Z","shell.execute_reply.started":"2024-06-06T07:33:29.863542Z","shell.execute_reply":"2024-06-06T07:33:29.871141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:34:19.638141Z","iopub.execute_input":"2024-06-06T07:34:19.638556Z","iopub.status.idle":"2024-06-06T07:34:19.646801Z","shell.execute_reply.started":"2024-06-06T07:34:19.638526Z","shell.execute_reply":"2024-06-06T07:34:19.645388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:34:21.588618Z","iopub.execute_input":"2024-06-06T07:34:21.589097Z","iopub.status.idle":"2024-06-06T07:34:21.599702Z","shell.execute_reply.started":"2024-06-06T07:34:21.589062Z","shell.execute_reply":"2024-06-06T07:34:21.598234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols_all = cat_cols","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:49:00.628150Z","iopub.execute_input":"2024-06-06T07:49:00.628596Z","iopub.status.idle":"2024-06-06T07:49:00.633590Z","shell.execute_reply.started":"2024-06-06T07:49:00.628561Z","shell.execute_reply":"2024-06-06T07:49:00.632401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgb_imp = pd.read_csv(MODEL/\"LightGBM_Feature_Imp.csv\")\ncat_imp = pd.read_csv(MODEL/\"CatBoost_Feature_Imp.csv\")\nlgb_imp['Cum_Imp'] = lgb_imp['perc_imp'].cumsum()\ncat_imp['Cum_Imp'] = cat_imp['perc_imp'].cumsum()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:47:37.902853Z","iopub.execute_input":"2024-06-06T07:47:37.903270Z","iopub.status.idle":"2024-06-06T07:47:37.918201Z","shell.execute_reply.started":"2024-06-06T07:47:37.903236Z","shell.execute_reply":"2024-06-06T07:47:37.916902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keepp 99% of Cumulative Feature Importance","metadata":{}},{"cell_type":"code","source":"rfe_cols = list(lgb_imp[lgb_imp['Cum_Imp']>0.99]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nlgb, lgb_pred, lgb_scores = Model_Utils.LightGBMClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_lgb)\nwith open('lgb_train_rfe_num_99.joblib', 'wb') as f:\n    joblib.dump(lgb, f)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T07:49:15.327705Z","iopub.execute_input":"2024-06-06T07:49:15.328158Z","iopub.status.idle":"2024-06-06T07:50:17.265648Z","shell.execute_reply.started":"2024-06-06T07:49:15.328126Z","shell.execute_reply":"2024-06-06T07:50:17.264028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_cols = list(cat_imp[cat_imp['Cum_Imp']>0.99]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nclf, y_pred, cat_scores = Model_Utils.CatBoostClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_catboost)\nwith open('catboost_train_rfe_num_99.joblib', 'wb') as f:\n    joblib.dump(clf, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keep 95% of Cumulative Feature Importance","metadata":{}},{"cell_type":"code","source":"rfe_cols = list(lgb_imp[lgb_imp['Cum_Imp']>0.95]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nlgb, lgb_pred, lgb_scores = Model_Utils.LightGBMClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_lgb)\nwith open('lgb_train_rfe_num_95.joblib', 'wb') as f:\n    joblib.dump(lgb, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_cols = list(cat_imp[cat_imp['Cum_Imp']>0.95]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nclf, y_pred, cat_scores = Model_Utils.CatBoostClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_catboost)\nwith open('catboost_train_rfe_num_95.joblib', 'wb') as f:\n    joblib.dump(clf, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keep 90% if Cumulative Feature Importance","metadata":{}},{"cell_type":"code","source":"rfe_cols = list(lgb_imp[lgb_imp['Cum_Imp']>0.9]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nlgb, lgb_pred, lgb_scores = Model_Utils.LightGBMClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_lgb)\nwith open('lgb_train_rfe_num_90.joblib', 'wb') as f:\n    joblib.dump(lgb, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_cols = list(cat_imp[cat_imp['Cum_Imp']>0.90]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nclf, y_pred, cat_scores = Model_Utils.CatBoostClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_catboost)\nwith open('catboost_train_rfe_num_90.joblib', 'wb') as f:\n    joblib.dump(clf, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keep 80% of Cumulative Feature Importance","metadata":{}},{"cell_type":"code","source":"rfe_cols = list(lgb_imp[lgb_imp['Cum_Imp']>0.8]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nlgb, lgb_pred, lgb_scores = Model_Utils.LightGBMClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_lgb)\nwith open('lgb_train_rfe_num_80.joblib', 'wb') as f:\n    joblib.dump(lgb, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_cols = list(cat_imp[cat_imp['Cum_Imp']>0.8]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nclf, y_pred, cat_scores = Model_Utils.CatBoostClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_catboost)\nwith open('catboost_train_rfe_num_80.joblib', 'wb') as f:\n    joblib.dump(clf, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keep 70% of Cumulative Feature Importance","metadata":{}},{"cell_type":"code","source":"rfe_cols = list(lgb_imp[lgb_imp['Cum_Imp']>0.7]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nlgb, lgb_pred, lgb_scores = Model_Utils.LightGBMClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_lgb)\nwith open('lgb_train_rfe_num_70.joblib', 'wb') as f:\n    joblib.dump(lgb, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_cols = list(cat_imp[cat_imp['Cum_Imp']>0.7]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nclf, y_pred, cat_scores = Model_Utils.CatBoostClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_catboost)\nwith open('catboost_train_rfe_num_70.joblib', 'wb') as f:\n    joblib.dump(clf, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keep 60% of Cumulative Feature Importance","metadata":{}},{"cell_type":"code","source":"rfe_cols = list(lgb_imp[lgb_imp['Cum_Imp']>0.6]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nlgb, lgb_pred, lgb_scores = Model_Utils.LightGBMClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_lgb)\nwith open('lgb_train_rfe_num_60.joblib', 'wb') as f:\n    joblib.dump(lgb, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_cols = list(cat_imp[cat_imp['Cum_Imp']>0.6]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nclf, y_pred, cat_scores = Model_Utils.CatBoostClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_catboost)\nwith open('catboost_train_rfe_num_60.joblib', 'wb') as f:\n    joblib.dump(clf, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keep 50% of Cumulative Feature Importance","metadata":{}},{"cell_type":"code","source":"rfe_cols = list(lgb_imp[lgb_imp['Cum_Imp']>0.5]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nlgb, lgb_pred, lgb_scores = Model_Utils.LightGBMClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_lgb)\nwith open('lgb_train_rfe_num_50.joblib', 'wb') as f:\n    joblib.dump(lgb, f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfe_cols = list(cat_imp[cat_imp['Cum_Imp']>0.5]['0'])\ncols = [x for x in X.columns if x not in rfe_cols]\ncat_cols = [x for x in cat_cols_all if x in cols]\nprint(len(cols))\nclf, y_pred, cat_scores = Model_Utils.CatBoostClassifier_pred(X[cols], y, X_test[cols], y_test, cat_cols, params_catboost)\nwith open('catboost_train_rfe_num_50.joblib', 'wb') as f:\n    joblib.dump(clf, f)","metadata":{},"execution_count":null,"outputs":[]}]}