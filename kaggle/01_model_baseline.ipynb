{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8586937,"sourceType":"datasetVersion","datasetId":5136026},{"sourceId":8604711,"sourceType":"datasetVersion","datasetId":5136208}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nfrom glob import glob\nfrom pathlib import Path\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nimport lightgbm as lgb\nimport torch\nimport torch.nn as nn\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom catboost import CatBoostClassifier, Pool\nimport xgboost\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-04T14:50:55.669113Z","iopub.execute_input":"2024-06-04T14:50:55.669612Z","iopub.status.idle":"2024-06-04T14:51:02.815155Z","shell.execute_reply.started":"2024-06-04T14:50:55.669567Z","shell.execute_reply":"2024-06-04T14:51:02.814012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT            = Path(\"/kaggle/input/home-credit-risk-dataset-corr-dropped-top-2\")\nSCHEMA_PATH     = Path(\"/kaggle/input/schema-home-credit-risk-data\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:51:06.640017Z","iopub.execute_input":"2024-06-04T14:51:06.640622Z","iopub.status.idle":"2024-06-04T14:51:06.645931Z","shell.execute_reply.started":"2024-06-04T14:51:06.640586Z","shell.execute_reply":"2024-06-04T14:51:06.644682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pl.read_csv(ROOT / 'model_abt_pl_corr2_drop.csv').to_pandas()\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:51:07.886550Z","iopub.execute_input":"2024-06-04T14:51:07.886978Z","iopub.status.idle":"2024-06-04T14:52:15.550506Z","shell.execute_reply.started":"2024-06-04T14:51:07.886943Z","shell.execute_reply":"2024-06-04T14:52:15.549408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:52:15.552755Z","iopub.execute_input":"2024-06-04T14:52:15.553211Z","iopub.status.idle":"2024-06-04T14:52:15.589073Z","shell.execute_reply.started":"2024-06-04T14:52:15.553153Z","shell.execute_reply":"2024-06-04T14:52:15.588007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_data_types(df, schema):\n    for col, dtype in schema.items():\n        if dtype == 'category':\n            dtype = 'object'\n        df[col] = df[col].astype(dtype)\n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:52:15.590683Z","iopub.execute_input":"2024-06-04T14:52:15.591426Z","iopub.status.idle":"2024-06-04T14:52:15.597379Z","shell.execute_reply.started":"2024-06-04T14:52:15.591375Z","shell.execute_reply":"2024-06-04T14:52:15.596185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model_Utils:\n    \"\"\"\n    Created by: Julie Anne Co, 2024\n    \n    Helper functions for modeling LightGBM & CatBoost\n    Model evaluation functions\n    \"\"\"\n    @staticmethod\n    def model_evals(y_true, y_proba, cutoff = 0.5):\n        from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, average_precision_score, roc_auc_score\n        \"\"\"\n        Returns model evaluation metrics for a binary classification model\n\n        Parameters:\n        -----------\n            y_true: int (0,1) \n                Actual binary labels\n\n            y_proba: float (between 0 and 1)\n                Probability scores output of model \n\n        Returns:\n        --------\n            result: dict\n                Dictionary of metrics and their results based on the input\n                    - event rate (% predicted 1's)\n                    - accuracy\n                    - roc_auc\n                    - pr_auc\n                    - recall\n                    - precision\n                    - f1\n                    - lift\n        \"\"\"\n\n        y_pred = (y_proba > cutoff).astype(int)\n\n        event_rate = y_pred.mean()\n\n        accuracy = accuracy_score(y_true, y_pred)\n\n        roc_auc = roc_auc_score(y_true, y_proba)\n\n        pr_auc = average_precision_score(y_true, y_proba)\n\n        recall = recall_score(y_true, y_pred)\n\n        precision = precision_score(y_true, y_pred)\n\n        f1 = f1_score(y_true, y_pred)\n\n        lift = recall / event_rate\n\n        return {'event_rate': event_rate,\n                'acc': accuracy, \n                'roc_auc': roc_auc,\n                'pr_auc': pr_auc, \n                'recall': recall, \n                'precision': precision, \n                'f1': f1, \n                'lift': lift}\n    \n    @staticmethod\n    def DumbClassifier(y_true):\n        \"\"\"\n        Predict 0 (majority class) for all\n        \"\"\"\n        import numpy as np\n        y_pred = np.zeros(len(y_true))\n        return y_pred\n    \n    @staticmethod\n    def RandomChanceClassifier(y_true):\n        \"\"\"\n        Predict random 1 based on event rate\n        \"\"\"\n        import numpy as np\n        y_pred = Model_Utils.DumbClassifier(y_true)\n        event = y_true.sum()\n        ind = np.random.randint(0, len(y_true), size=event)\n        y_pred[ind] = 1\n        return y_pred\n    \n    @staticmethod\n    def save_model_results(results, schema, filepath):\n        \"\"\"\n        Save Model Results in csv\n        \"\"\"\n        if not os.path.exists(filepath):\n            score_schema = {'model_name': 'str', \n                        'model': 'str',\n                        'params': 'str',\n                        'acc': 'float',\n                        'precision': 'float',\n                        'recall': 'float',\n                        'f1_score': 'float',\n                        'roc_auc': 'float',\n                        'pr_auc': 'float',\n                        'lift': 'float'}\n            scores = pd.DataFrame(columns = score_schema.keys()).astype(score_schema)\n        else:\n            scores = pd.read_csv(filepath)\n        row = []\n        \n        for key in schema.keys():\n            row.append(results[key])\n        \n        scores.loc[len(scores)] = row\n        scores.to_csv(filepath, index = False)\n        \n    @staticmethod\n    def LightGBMClassifier_CV(X, y, cat_cols, cv = 5, group = None, params = None):\n        \"\"\"\n        K-Fold Average peformance of a LigthGBM estimator\n        \"\"\"\n        import lightgbm\n        from sklearn.model_selection import StratifiedGroupKFold\n        \n        cv = StratifiedGroupKFold(n_splits=cv, shuffle = True, random_state = 42)\n        \n        if params == None:\n            params = {'random_state': 42\n                     ,'objective': 'binary'\n                     ,'verbose': -1\n                     ,'n_jobs': -1}\n        \n        scores = {'params': params,\n                        'acc': [],\n                        'precision': [],\n                        'recall': [],\n                        'f1_score': [],\n                        'roc_auc': [],\n                        'pr_auc': [],\n                        'lift': []}\n\n        split = 1\n        \n        for train_ind, valid_ind in cv.split(X, y, groups=group):\n            X_train, y_train = X.iloc[train_ind], y.iloc[train_ind]\n            X_valid, y_valid = X.iloc[valid_ind], y.iloc[valid_ind]\n\n            X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n            X_valid[cat_cols] = X_valid[cat_cols].astype(\"category\")\n\n            lgb = lightgbm.LGBMClassifier(**params)\n            lgb.fit(X_train, y_train)\n            print(lgb.get_params(deep=True))\n            print(lgb._other_params)\n\n            y_proba = lgb.predict_proba(X_valid)[:, 1]\n            results = Model_Utils.model_evals(y_valid, y_proba)\n            print(f'LightGBM, Val CV{split}: {results}\"')\n            \n            split += 1\n            \n            for key in results.keys():\n                if key in scores.keys():\n                    scores[key].append(results[key])\n        \n        for key in results.keys():\n            if key in scores.keys():\n                scores[key] = np.array(scores[key]).mean()\n        \n        return scores\n\n    \n    @staticmethod\n    def train_test_split(X, y, test_size = 0.2):\n        \"\"\"\n        Split data into train-test\n        \"\"\"\n        from sklearn.model_selection import train_test_split\n        import polars as pl\n        \n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n        \n        print(f\"X_train: {X_train.shape}\")\n        print(f\"y_train: {y_train.shape}\")\n        #pl.from_pandas(pd.concat([y_train, X_train], axis = 1)).write_csv('model_abt_train.csv')\n        del X_train\n        del y_train\n        gc.collect()\n        \n        print(f\"X_test: {X_test.shape}\")\n        print(f\"y_test: {y_test.shape}\")\n        pl.from_pandas(pd.concat([y_test, X_test], axis = 1)).write_csv('model_abt_test.csv')\n        del X_test\n        del y_test\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:52:15.601022Z","iopub.execute_input":"2024-06-04T14:52:15.601527Z","iopub.status.idle":"2024-06-04T14:52:15.631190Z","shell.execute_reply.started":"2024-06-04T14:52:15.601493Z","shell.execute_reply":"2024-06-04T14:52:15.630046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"schema = pd.read_csv(SCHEMA_PATH / \"data_schema.csv\", names = ['Columns', 'dtype'])\nschema = schema[schema['Columns'].isin(df.columns)]\nschema = schema.set_index('Columns')['dtype'].to_dict()\nset(schema.values())","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:52:15.632514Z","iopub.execute_input":"2024-06-04T14:52:15.632869Z","iopub.status.idle":"2024-06-04T14:52:15.666877Z","shell.execute_reply.started":"2024-06-04T14:52:15.632810Z","shell.execute_reply":"2024-06-04T14:52:15.665763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"non_feat = ['case_id', 'WEEK_NUM', 'decision_month', 'decision_weekday', 'target']\nnum_cols = [x for x, dtype in schema.items() if x not in non_feat and dtype in ['int64', 'float64', 'int8']]\ncat_cols = [x for x, dtype in schema.items() if x not in non_feat and dtype == 'category']","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:52:15.668096Z","iopub.execute_input":"2024-06-04T14:52:15.668386Z","iopub.status.idle":"2024-06-04T14:52:15.674742Z","shell.execute_reply.started":"2024-06-04T14:52:15.668360Z","shell.execute_reply":"2024-06-04T14:52:15.673647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = set_data_types(df, schema)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:52:15.676038Z","iopub.execute_input":"2024-06-04T14:52:15.676347Z","iopub.status.idle":"2024-06-04T14:53:07.591978Z","shell.execute_reply.started":"2024-06-04T14:52:15.676304Z","shell.execute_reply":"2024-06-04T14:53:07.591029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_val = df[['case_id', 'WEEK_NUM', 'target', 'decision_month', 'decision_weekday']]\ny = df['target']\nX = df[num_cols + cat_cols]\ndel df","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:53:07.593108Z","iopub.execute_input":"2024-06-04T14:53:07.593387Z","iopub.status.idle":"2024-06-04T14:53:12.870980Z","shell.execute_reply.started":"2024-06-04T14:53:07.593362Z","shell.execute_reply":"2024-06-04T14:53:12.870036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Split Data into Train & Test\nWe will get 20% of the data as holdout. We will tune our model on the 80%.","metadata":{}},{"cell_type":"code","source":"Model_Utils.train_test_split(X, y)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:53:12.872760Z","iopub.execute_input":"2024-06-04T14:53:12.873210Z","iopub.status.idle":"2024-06-04T14:53:41.813714Z","shell.execute_reply.started":"2024-06-04T14:53:12.873172Z","shell.execute_reply":"2024-06-04T14:53:41.812567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.read_csv('model_abt_test.csv').head()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:53:41.816962Z","iopub.execute_input":"2024-06-04T14:53:41.817296Z","iopub.status.idle":"2024-06-04T14:53:46.271259Z","shell.execute_reply.started":"2024-06-04T14:53:41.817268Z","shell.execute_reply":"2024-06-04T14:53:46.269912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### We will define our baseline vs Random Classifier (random chance) and a Dumb Classifier (predict all majority class). Optimized models should be able to beat these 2.\n","metadata":{}},{"cell_type":"code","source":"score_schema = {'model_name': 'str', \n                        'model': 'str',\n                        'params': 'str',\n                        'acc': 'float',\n                        'precision': 'float',\n                        'recall': 'float',\n                        'f1': 'float',\n                        'roc_auc': 'float',\n                        'pr_auc': 'float',\n                        'lift': 'float'}","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:53:54.229323Z","iopub.execute_input":"2024-06-04T14:53:54.229772Z","iopub.status.idle":"2024-06-04T14:53:54.236190Z","shell.execute_reply.started":"2024-06-04T14:53:54.229739Z","shell.execute_reply":"2024-06-04T14:53:54.235069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Dumb Classifier\n","metadata":{}},{"cell_type":"code","source":"results  = Model_Utils.model_evals(y, Model_Utils.DumbClassifier(y))\nprint(results)\nresults['model_name'] = 'Dumb Classifier'\nresults['model'] = 'Predict All Major'\nresults['params'] = None\nModel_Utils.save_model_results(results, score_schema, \"baseline.csv\")\ndel results\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:53:56.693788Z","iopub.execute_input":"2024-06-04T14:53:56.694215Z","iopub.status.idle":"2024-06-04T14:53:59.263460Z","shell.execute_reply.started":"2024-06-04T14:53:56.694181Z","shell.execute_reply":"2024-06-04T14:53:59.262389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Random Chance Classifier","metadata":{}},{"cell_type":"code","source":"results  = Model_Utils.model_evals(y, Model_Utils.RandomChanceClassifier(y))\nprint(results)\nresults['model_name'] = 'Random Chance Classifier'\nresults['model'] = 'Randomly Predict at Event Rate'\nresults['params'] = None\nModel_Utils.save_model_results(results, score_schema, \"baseline.csv\")\ndel results\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T14:54:02.862003Z","iopub.execute_input":"2024-06-04T14:54:02.862404Z","iopub.status.idle":"2024-06-04T14:54:05.499257Z","shell.execute_reply.started":"2024-06-04T14:54:02.862372Z","shell.execute_reply":"2024-06-04T14:54:05.498205Z"},"trusted":true},"execution_count":null,"outputs":[]}]}